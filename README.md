<h1 align="center">Huia Echo ğŸ¸</h1>

# ğŸ‘ï¸â€ğŸ—¨ï¸ Mobility Aid for Visually Impaired Users

A low-cost embedded system designed to assist visually impaired individuals using real-time **proximity sensing** and **traffic light recognition**. Built on a Raspberry Pi, the system integrates ultrasonic sensors, a camera, and a lightweight machine learning model (YOLOv11n) to detect environmental conditions and provide haptic feedback.

---

## ğŸ“Œ Overview

This mobility aid project helps users safely navigate streets, particularly at pedestrian crossings. The system combines:

- **Ultrasonic sensing** to detect nearby obstacles
- **Traffic light recognition** using a camera and an efficient YOLOv11n model
- **Feedback mechanism** via vibration, triggered based on proximity and light state

---

## ğŸ“ Key File Structure

```
mobility-aid/
â”‚
â”œâ”€â”€ include/                  # C header files
â”‚   â”œâ”€â”€ config_loader.h       # Loads external config values
â”‚   â”œâ”€â”€ gpio_functions.h      # GPIO pin setup and control
â”‚   â””â”€â”€ tick.h                # Timing utilities
â”‚
â”œâ”€â”€ src/                      # C source files
â”‚   â”œâ”€â”€ configs/              # Config database using data generated by web app
â”‚   â”‚   â””â”€â”€ config.db
â”‚   â”œâ”€â”€ prox_sensor.c         # Ultrasonic sensor and control loop
â”‚   â””â”€â”€ start.py              # Orchestrates all components (C binary, ML, server)               
â”‚
â”œâ”€â”€ ml/                       # Machine learning module
â”‚   â”œâ”€â”€ augmentation.ipynb    # Data augmentation and preprocessing
â”‚   â”œâ”€â”€ train_model.ipynb     # YOLOv11n training logic
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ best.pt           # Trained YOLOv11n model weights
â”‚
â”œâ”€â”€ web/                      # Web interface (Flask app)
â”‚   â””â”€â”€ app.py                # Local dashboard
â”‚
â”œâ”€â”€ Makefile                  # Compiles the C code
â”œâ”€â”€ .gitignore
â”œâ”€â”€ start.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md                 
```

---

## ğŸš€ Features

- ğŸ“¡ **Ultrasonic Sensing**  
  Detects objects and measures distance with HC-SR04 sensor.

- ğŸ§  **Traffic Light Recognition (YOLOv11n)**  
  Recognizes red/green pedestrian and traffic lights from a camera feed.

- ğŸ”Š **Feedback System**  
  Triggers vibration when objects are too close or crossing is unsafe.

- âš™ï¸ **Modular Design**  
  Split into embedded C for performance and Python for AI tasks.

- ğŸª› **Easily Configurable**  
  Adjust logic thresholds via external config files.

---

## ğŸ§  Machine Learning

- **Model:** YOLOv11n (Ultralytics)
- **Dataset:** Custom images gathered and augmented to increase dataset size
- **Use Case:** Detect green/red pedestrian signals in real time
- **Output:** Torch `.pt` model located at `ml/models/best.pt`
- **Trained Using:**  
  - `augmentation.ipynb`: Image resizing, color shifts, flips  
  - `train_model.ipynb`: Fine-tuning YOLOv11n with labeled traffic light data

## ğŸ–¥ï¸ Requirements

### Hardware

- Raspberry Pi 4 (or newer)
- HC-SR04 Ultrasonic sensor
- Pi Camera Module
- Vibration motor or buzzer

---
