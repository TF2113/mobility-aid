{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TF2113/mobility-aid/blob/master/augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnWJSKtNyL-D"
      },
      "source": [
        "# Image Augumentation using Albumentations\n",
        "\n",
        "Apply data augmentation to a directory of images using Albumentations library for Python. A tool for increasing the amount of viable data for training machine learning models on a small initial dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lg_liL-zQT1"
      },
      "source": [
        "#Required Libraries and Packages Installer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC9Ub8No0SpU"
      },
      "source": [
        "Code snippet to install all requirements for Albumentations to run correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmMdmTc3zTew",
        "outputId": "11a2e3cc-1882-4496-94d1-16115de86207"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Setup complete! You can now access your images and use Albumentations.\n"
          ]
        }
      ],
      "source": [
        "# Install required packages quietly\n",
        "!pip install albumentations opencv-python matplotlib --quiet\n",
        "\n",
        "# Imports\n",
        "import os\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to access files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"Setup complete! You can now access your images and use Albumentations.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO0MF0LJ0yPi"
      },
      "source": [
        "# Set Input and Output Directories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fQuUjcL06ju"
      },
      "source": [
        "Upload data.zip containing labelled images in YOLO format to be unzipped. Made using Label Studio for this project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_IfCDHx04lL",
        "outputId": "6c3a223a-e471-4152-8617-5d4b7f72edee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data extracted to: /content/drive/MyDrive/\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/data.zip'   # Path to zip file containing images and labels\n",
        "extract_to = '/content/drive/MyDrive/'         # Path to extract data to\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(f\"Data extracted to: {extract_to}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_YKswJ-5HPB"
      },
      "source": [
        "Set path to input/output directories for storing augmented images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLVSFTDq5FUk",
        "outputId": "5f1cc570-5d87-4851-d515-89f4c3cd502c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input images: /content/drive/MyDrive/images\n",
            "Input labels: /content/drive/MyDrive/labels\n",
            "Output images: /content/drive/MyDrive/aug_images\n",
            "Output labels: /content/drive/MyDrive/aug_labels\n"
          ]
        }
      ],
      "source": [
        "input_img_dir = '/content/drive/MyDrive/images'         # Your images folder\n",
        "input_label_dir = '/content/drive/MyDrive/labels'       # Your YOLO txt labels folder\n",
        "\n",
        "output_img_dir = '/content/drive/MyDrive/aug_images'    # Where augmented images go\n",
        "output_label_dir = '/content/drive/MyDrive/aug_labels'  # Where augmented labels go\n",
        "\n",
        "os.makedirs(output_img_dir, exist_ok=True)\n",
        "os.makedirs(output_label_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Input images: {input_img_dir}\")\n",
        "print(f\"Input labels: {input_label_dir}\")\n",
        "print(f\"Output images: {output_img_dir}\")\n",
        "print(f\"Output labels: {output_label_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ija2j5OhI7mk"
      },
      "source": [
        "#Helper Functions for Reading/Writing Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRYh_2FgSKEs"
      },
      "source": [
        "Code to define two functions that will read and write YOLO label files when needed for Albumentations augmentations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDZ8xcBhJGPY"
      },
      "outputs": [],
      "source": [
        "def read_yolo_labels(label_file_path):\n",
        "  bounding_boxes = []\n",
        "  class_ids = []\n",
        "  with open(label_file_path, 'r') as label_file: # Open .txt file for image label\n",
        "    for line in label_file:\n",
        "      sections = line.strip().split()            # Split each line into sections\n",
        "      class_id = int(sections[0])                # YOLO label format begins with class ids\n",
        "      bounding_box = []\n",
        "      for part in sections[1:5]:                 # Next section in YOLO format is the x,y of the bounding boxes\n",
        "        bounding_box.append(float(part))         # alongside the height and width of the box\n",
        "      class_ids.append(class_id)\n",
        "      bounding_boxes.append(bounding_box)\n",
        "  return bounding_boxes, class_ids               # Return arrays containing locations for all bounding boxes and labels in the image\n",
        "\n",
        "def save_yolo_labels(label_path, bounding_boxes, class_ids):\n",
        "    with open(label_path, 'w') as label_file:                               # Open file to save to\n",
        "        for class_id, bounding_box in zip(class_ids, bounding_boxes):\n",
        "            formatted_coords = []\n",
        "            for coord in bounding_box:\n",
        "                formatted_coord = format(coord, \".6f\")                      # Format coords to 6 decimal places\n",
        "                formatted_coords.append(formatted_coord)\n",
        "\n",
        "            bounding_box_line = f\"{class_id} \" + ' '.join(formatted_coords) # Saves formatted line to the file (Formatted example = 1 0.123456 0.123456 0.123456 0.123456)\n",
        "            label_file.write(bounding_box_line + \"\\n\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJzqse5sr-V1"
      },
      "source": [
        "#Augmentation Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcEF4FRdsCOJ"
      },
      "source": [
        "Defining the image augmentations to be used and their probabilities of being applied for each image. Augmentations are applied randomly to improve diversity of the data and help avoid overfitting to similar images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNiPTtufuJaw"
      },
      "outputs": [],
      "source": [
        "pipeline = A.Compose([\n",
        "    A.RandomSizedBBoxSafeCrop(height = 640, width = 640, p=0.75),\n",
        "    A.HorizontalFlip(p=0.6),\n",
        "    A.SafeRotate(limit=[-10, 10], p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.RandomGamma(p=0.4),\n",
        "    A.GaussianBlur(p=0.3),\n",
        "    A.GaussNoise(p=0.15),\n",
        "    A.RandomRain(p=0.2),\n",
        "    A.RandomFog(p=0.05),\n",
        "    A.RandomSunFlare(p=0.05),\n",
        "    A.Resize(height = 640, width = 640)\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_ids']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkgDUkj8N9oI"
      },
      "source": [
        "# Augmenting the Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UT_B45VQ5dc"
      },
      "source": [
        "Applying the defined pipeline to each image in the */image* directory 5 times to provide a diverse dataset of ~300 images from the initial dataset of 61 images, outputting to the */aug_images* directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06t3dN0JRFJ6"
      },
      "outputs": [],
      "source": [
        "for file in os.listdir(input_img_dir):\n",
        "  if not file.lower().endswith(\".jpeg\"):\n",
        "    continue\n",
        "\n",
        "  img_path = os.path.join(input_img_dir, file)\n",
        "  label_path = os.path.join(input_label_dir, file.replace(\".jpeg\", \".txt\"))\n",
        "\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  bounding_boxes, class_ids = read_yolo_labels(label_path)\n",
        "\n",
        "  for i in range(5):\n",
        "    augmented_image = pipeline(image=img, bboxes=bounding_boxes, class_ids=class_ids)\n",
        "    aug_img = augmented_image['image']\n",
        "    aug_bounding_boxes = augmented_image['bboxes']\n",
        "    aug_class_ids = augmented_image['class_ids']\n",
        "\n",
        "    file_name = os.path.splitext(file)[0]\n",
        "    aug_img_bgr = cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR)\n",
        "    aug_image_path = os.path.join(output_img_dir, f\"{file_name}_aug{i}.jpeg\")\n",
        "    aug_label_path = os.path.join(output_label_dir, f\"{file_name}_aug{i}.txt\")\n",
        "\n",
        "    cv2.imwrite(aug_image_path, aug_img_bgr)\n",
        "    save_yolo_labels(aug_label_path, aug_bounding_boxes, aug_class_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltDEuvHKZPC6"
      },
      "source": [
        "Zip all image and label data to be used in training the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8EAvuOqtYbEu"
      },
      "outputs": [],
      "source": [
        "!zip -r data.zip /content/drive/MyDrive/aug_images /content/drive/MyDrive/aug_labels /content/drive/MyDrive/images /content/drive/MyDrive/labels -quiet\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPNL1RUQBi0hTlSub/jKjoz",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
